{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Azure AI Search\n",
    "\n",
    "[Azure AI Search](https://learn.microsoft.com/azure/search/search-what-is-azure-search) (formerly known as `Azure Search` and `Azure Cognitive Search`) is a cloud search service that gives developers infrastructure, APIs, and tools for information retrieval of vector, keyword, and hybrid queries at scale.\n",
    "\n",
    "You'll need to install `langchain-community` with `pip install -qU langchain-community` to use this integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Azure AI Search SDK\n",
    "\n",
    "Use azure-search-documents package version 11.4.0 or later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain/blob/master/templates/rag-azure-search/README.md\n",
    "https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/vectorstores/azuresearch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  azure-search-documents\n",
    "%pip install --upgrade --quiet  azure-identity\n",
    "%pip install --upgrade --quiet  langchain-community\n",
    "%pip install --upgrade --quiet  langchain_openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries\n",
    "\n",
    "`OpenAIEmbeddings` is assumed, but if you're using Azure OpenAI, import `AzureOpenAIEmbeddings` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure OpenAI settings\n",
    "Set variables for your OpenAI provider. You need either an [OpenAI account](https://platform.openai.com/docs/quickstart?context=python) or an [Azure OpenAI account](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource) to generate the embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Get configuration settings\n",
    "load_dotenv()\n",
    "# use an Azure OpenAI account with a deployment of an embedding model\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(azure_endpoint)\n",
    "print(azure_deployment)\n",
    "print(azure_openai_api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure vector store settings\n",
    "\n",
    "You need an [Azure subscription](https://azure.microsoft.com/en-us/free/search) and [Azure AI Search service](https://learn.microsoft.com/azure/search/search-create-service-portal) to use this vector store integration. No-cost versions are available for small and limited workloads.\n",
    " \n",
    "Set variables for your Azure AI Search URL and admin API key. You can get these variables from the [Azure portal](https://portal.azure.com/#blade/HubsExtension/BrowseResourceBlade/resourceType/Microsoft.Search%2FsearchServices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_address: str = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "vector_store_password: str = os.getenv(\"AZURE_SEARCH_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings and vector store instances\n",
    " \n",
    "Create instances of the OpenAIEmbeddings and AzureSearch classes. When you complete this step, you should have an empty search index on your Azure AI Search resource. The integration module provides a default schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AzureOpenAIEmbeddings with an Azure account\n",
    "embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector store instance\n",
    " \n",
    "Create instance of the AzureSearch class using the embeddings from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name: str = \"langchain-vector-index\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.embed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify additional properties for the Azure client such as the following https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md#configurations\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    # Configure max retries for the Azure client\n",
    "    additional_search_client_options={\"retry_total\": 4},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    " \n",
    "This step loads, chunks, and vectorizes the sample document, and then indexes the content into a search index on Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/langchain-ai/langchain/issues/11313\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = CSVLoader(\"./data/WineDataset.csv\",  encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# You might experience RequestEntityTooLargeError, to address this you can modify the batch size and chunk_size.\n",
    "#vector_store.add_documents(documents=docs)\n",
    "\n",
    "batch_size = 100  # Set batch size, adjust according to Azure's limitations\n",
    "for i in range(0, len(docs), batch_size):\n",
    "    batch = docs[i:i + batch_size]\n",
    "    vector_store.add_documents(documents=batch)  # Add smaller batches\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search\n",
    " \n",
    "Execute a pure vector similarity search using the similarity_search() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What are the most expensive wines that won an IWC award\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(docs)\n",
    "#print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search with relevance scores\n",
    " \n",
    "Execute a pure vector similarity search using the similarity_search_with_relevance_scores() method. Queries that don't meet the threshold requirements are exluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_and_scores = vector_store.similarity_search_with_relevance_scores(\n",
    "    query=\"Which red wines go well with red meat?\",\n",
    "    k=4,\n",
    "    score_threshold=0.64,\n",
    ")\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(docs_and_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search\n",
    "\n",
    "Execute hybrid search using the search_type or hybrid_search() method. Vector and nonvector text fields are queried in parallel, results are merged, and top matches of the unified result set are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hybrid search using the search_type parameter\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"Which red wines go well with red meat?\",\n",
    "    k=3,\n",
    "    search_type=\"hybrid\",\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a hybrid search using the hybrid_search method\n",
    "docs = vector_store.hybrid_search(\n",
    "    query=\"Which red wines go well with red meat?\", k=3\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom schemas and queries\n",
    "\n",
    "This section shows you how to replace the default schema with a custom schema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new index with custom filterable fields \n",
    "\n",
    "This schema shows field definitions. It's the default schema, plus several new fields attributed as filterable. Because it's using the default vector configuration, you won't see vector configuration or vector profile overrides here. The name of the default vector profile is \"myHnswProfile\" and it's using a vector configuration of Hierarchical Navigable Small World (HNSW) for indexing and queries against the content_vector field.\n",
    "\n",
    "There's no data for this schema in this step. When you execute the cell, you should get an empty index on Azure AI Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hierarchical Navigable Small World (HNSW)\n",
    "### Purpose: \n",
    "HNSW is an approximate nearest neighbor (ANN) algorithm. It’s designed to quickly find the nearest vectors (similar documents or search results) to a query vector, while maintaining good accuracy.\n",
    "How It Works: HNSW uses a graph-based approach where data points (vectors) are stored as nodes in a multi-layer graph. When searching for the nearest neighbors, it navigates through these layers in a hierarchical manner. The higher layers of the graph contain fewer nodes but help in quickly narrowing down the search space, while lower layers contain more nodes for a more detailed search.\n",
    "### Advantages:\n",
    "Speed: HNSW is very fast for large datasets due to its approximate nature. It doesn't compare every vector in the dataset, instead navigating the graph structure to reach a result quickly.\n",
    "Scalability: It scales well with large datasets, making it ideal for search indexes where speed is a priority.\n",
    "Memory Efficient: It has optimized memory usage compared to brute-force methods.\n",
    "### Disadvantages:\n",
    "Approximate Results: Since it is an approximate algorithm, the search results may not always be the true nearest neighbors. However, the trade-off in accuracy is often minimal and acceptable for most applications.\n",
    "## 2. Exhaustive KNN (K-Nearest Neighbor)\n",
    "### Purpose: \n",
    "Exhaustive KNN is a brute-force nearest neighbor search algorithm. It computes the distance between the query vector and every other vector in the dataset, ensuring the most accurate nearest neighbors.\n",
    "How It Works: For each query, exhaustive KNN compares the query vector to all vectors in the dataset and returns the k vectors that are closest to the query based on a similarity measure (like cosine similarity or Euclidean distance).\n",
    "### Advantages:\n",
    "Accuracy: This method guarantees the exact nearest neighbors, making it the most accurate method.\n",
    "Simplicity: It’s straightforward in implementation, as it does not require building complex data structures like in HNSW.\n",
    "### Disadvantages:\n",
    "Speed: Exhaustive KNN is significantly slower than approximate methods, especially with large datasets, as it needs to compute distances for every vector in the dataset.\n",
    "Scalability: It becomes inefficient as the dataset grows larger, making it less suitable for real-time applications where speed is critical.\n",
    "Resource Intensive: Since it processes every vector in the dataset, it requires more computation and memory resources compared to HNSW.\n",
    "## When to Use:\n",
    "### HNSW:\n",
    "Ideal for large datasets and applications where speed is critical, like real-time search and recommendation systems.\n",
    "Suitable for use cases where approximate results are acceptable, such as similarity-based search in AI-driven applications.\n",
    "### Exhaustive KNN:\n",
    "Best for small to medium datasets or cases where absolute accuracy is required, such as scientific applications or high-precision recommendation systems.\n",
    "Suitable for batch processing scenarios where speed is not a priority but accuracy is paramount.\n",
    "## Summary:\n",
    "HNSW offers faster and more scalable performance with approximate results, making it the go-to choice for real-time, large-scale vector search applications.\n",
    "Exhaustive KNN provides exact results but is slower and less scalable, best used for small datasets or when absolute accuracy is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field to store the title\n",
    "    SearchableField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "index_name: str = \"langchain-vector-index-custom\"\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embedding_function,\n",
    "    fields=fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data and perform a query that includes a filter\n",
    "\n",
    "This example adds data to the vector store based on the custom schema. It loads text into the title and source fields. The source field is filterable. The sample query in this section filters the results based on content in the source field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data in the metadata dictionary with a corresponding field in the index will be added to the index.\n",
    "# In this example, the metadata dictionary contains a title, a source, and a random field.\n",
    "# The title and the source are added to the index as separate fields, but the random value is ignored because it's not defined in the schema.\n",
    "# The random field is only stored in the metadata field.\n",
    "vector_store.add_texts(\n",
    "    [\"Test 1\", \"Test 2\", \"Test 3\"],\n",
    "    [\n",
    "        {\"title\": \"Title 1\", \"source\": \"A\", \"random\": \"10290\"},\n",
    "        {\"title\": \"Title 2\", \"source\": \"A\", \"random\": \"48392\"},\n",
    "        {\"title\": \"Title 3\", \"source\": \"B\", \"random\": \"32893\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vector_store.similarity_search(query=\"Test 3 source1\", k=3, search_type=\"hybrid\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vector_store.similarity_search(\n",
    "    query=\"Test 3 source1\", k=3, search_type=\"hybrid\", filters=\"source eq 'A'\"\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new index with a scoring profile\n",
    "\n",
    "Here's another custom schema that includes a scoring profile definition. A scoring profile is used for relevance tuning of nonvector content, which is helpful in hybrid search scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    FreshnessScoringFunction,\n",
    "    FreshnessScoringParameters,\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "#  Azure OpenAI is your provider.\n",
    "embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field to store the title\n",
    "    SearchableField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    # Additional data field for last doc update\n",
    "    SimpleField(\n",
    "        name=\"last_update\",\n",
    "        type=SearchFieldDataType.DateTimeOffset,\n",
    "        searchable=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "]\n",
    "# Adding a custom scoring profile with a freshness function\n",
    "sc_name = \"custom_scoring_profile\"\n",
    "sc = ScoringProfile(\n",
    "    name=sc_name,\n",
    "    text_weights=TextWeights(weights={\"title\": 5}),\n",
    "    function_aggregation=\"sum\",\n",
    "    functions=[\n",
    "        FreshnessScoringFunction(\n",
    "            field_name=\"last_update\",\n",
    "            boost=100,\n",
    "            parameters=FreshnessScoringParameters(boosting_duration=\"P2D\"),\n",
    "            interpolation=\"linear\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "index_name = \"langchain-vector-custom-scoring-profile\"\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    fields=fields,\n",
    "    scoring_profiles=[sc],\n",
    "    default_scoring_profile=sc_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding same data with different last_update to show Scoring Profile effect\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "today = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n",
    "yesterday = (datetime.utcnow() - timedelta(days=1)).strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n",
    "one_month_ago = (datetime.utcnow() - timedelta(days=30)).strftime(\n",
    "    \"%Y-%m-%dT%H:%M:%S-00:00\"\n",
    ")\n",
    "\n",
    "vector_store.add_texts(\n",
    "    [\"Test 1\", \"Test 1\", \"Test 1\"],\n",
    "    [\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"10290\",\n",
    "            \"last_update\": today,\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"48392\",\n",
    "            \"last_update\": yesterday,\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"32893\",\n",
    "            \"last_update\": one_month_ago,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vector_store.similarity_search(query=\"Test 1\", k=3, search_type=\"similarity\")\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
