{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Azure AI Search\n",
    "\n",
    "[Azure AI Search](https://learn.microsoft.com/azure/search/search-what-is-azure-search) (formerly known as `Azure Search` and `Azure Cognitive Search`) is a cloud search service that gives developers infrastructure, APIs, and tools for information retrieval of vector, keyword, and hybrid queries at scale.\n",
    "\n",
    "You'll need to install `langchain-community` with `pip install -qU langchain-community` to use this integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Azure AI Search SDK\n",
    "\n",
    "Use azure-search-documents package version 11.4.0 or later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain/blob/master/templates/rag-azure-search/README.md\n",
    "https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/vectorstores/azuresearch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  azure-search-documents\n",
    "%pip install --upgrade --quiet  azure-identity\n",
    "%pip install --upgrade --quiet  langchain-community\n",
    "%pip install --upgrade --quiet  langchain_openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries\n",
    "\n",
    "`OpenAIEmbeddings` is assumed, but if you're using Azure OpenAI, import `AzureOpenAIEmbeddings` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure OpenAI settings\n",
    "Set variables for your OpenAI provider. You need either an [OpenAI account](https://platform.openai.com/docs/quickstart?context=python) or an [Azure OpenAI account](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource) to generate the embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Get configuration settings\n",
    "load_dotenv()\n",
    "# use an Azure OpenAI account with a deployment of an embedding model\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://demooai01.openai.azure.com/\n",
      "text-embedding-3-large\n",
      "2024-09-01-preview\n"
     ]
    }
   ],
   "source": [
    "print(azure_endpoint)\n",
    "print(azure_deployment)\n",
    "print(azure_openai_api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure vector store settings\n",
    "\n",
    "You need an [Azure subscription](https://azure.microsoft.com/en-us/free/search) and [Azure AI Search service](https://learn.microsoft.com/azure/search/search-create-service-portal) to use this vector store integration. No-cost versions are available for small and limited workloads.\n",
    " \n",
    "Set variables for your Azure AI Search URL and admin API key. You can get these variables from the [Azure portal](https://portal.azure.com/#blade/HubsExtension/BrowseResourceBlade/resourceType/Microsoft.Search%2FsearchServices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_address: str = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "vector_store_password: str = os.getenv(\"AZURE_SEARCH_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings and vector store instances\n",
    " \n",
    "Create instances of the OpenAIEmbeddings and AzureSearch classes. When you complete this step, you should have an empty search index on your Azure AI Search resource. The integration module provides a default schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AzureOpenAIEmbeddings with an Azure account\n",
    "embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector store instance\n",
    " \n",
    "Create instance of the AzureSearch class using the embeddings from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name: str = \"langchain-vector-index\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method OpenAIEmbeddings.embed_query of AzureOpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x00000201744118B0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x0000020174CA96A0>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-3-large', openai_api_version='2024-09-01-preview', openai_api_base=None, openai_api_type='azure', openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=2048, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True, azure_endpoint='https://demooai01.openai.azure.com/', azure_ad_token=None, azure_ad_token_provider=None, validate_base_url=True)>\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.embed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify additional properties for the Azure client such as the following https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md#configurations\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    # Configure max retries for the Azure client\n",
    "    additional_search_client_options={\"retry_total\": 4},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    " \n",
    "This step loads, chunks, and vectorizes the sample document, and then indexes the content into a search index on Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 670, which is longer than the specified 500\n",
      "Created a chunk of size 625, which is longer than the specified 500\n",
      "Created a chunk of size 610, which is longer than the specified 500\n",
      "Created a chunk of size 536, which is longer than the specified 500\n",
      "Created a chunk of size 705, which is longer than the specified 500\n",
      "Created a chunk of size 513, which is longer than the specified 500\n",
      "Created a chunk of size 518, which is longer than the specified 500\n",
      "Created a chunk of size 618, which is longer than the specified 500\n",
      "Created a chunk of size 656, which is longer than the specified 500\n",
      "Created a chunk of size 605, which is longer than the specified 500\n",
      "Created a chunk of size 730, which is longer than the specified 500\n",
      "Created a chunk of size 624, which is longer than the specified 500\n",
      "Created a chunk of size 509, which is longer than the specified 500\n",
      "Created a chunk of size 615, which is longer than the specified 500\n",
      "Created a chunk of size 1026, which is longer than the specified 500\n",
      "Created a chunk of size 718, which is longer than the specified 500\n",
      "Created a chunk of size 658, which is longer than the specified 500\n",
      "Created a chunk of size 764, which is longer than the specified 500\n",
      "Created a chunk of size 624, which is longer than the specified 500\n",
      "Created a chunk of size 614, which is longer than the specified 500\n",
      "Created a chunk of size 1022, which is longer than the specified 500\n",
      "Created a chunk of size 777, which is longer than the specified 500\n",
      "Created a chunk of size 695, which is longer than the specified 500\n",
      "Created a chunk of size 539, which is longer than the specified 500\n",
      "Created a chunk of size 691, which is longer than the specified 500\n",
      "Created a chunk of size 521, which is longer than the specified 500\n",
      "Created a chunk of size 626, which is longer than the specified 500\n",
      "Created a chunk of size 836, which is longer than the specified 500\n",
      "Created a chunk of size 610, which is longer than the specified 500\n",
      "Created a chunk of size 591, which is longer than the specified 500\n",
      "Created a chunk of size 723, which is longer than the specified 500\n",
      "Created a chunk of size 589, which is longer than the specified 500\n",
      "Created a chunk of size 563, which is longer than the specified 500\n",
      "Created a chunk of size 827, which is longer than the specified 500\n",
      "Created a chunk of size 765, which is longer than the specified 500\n",
      "Created a chunk of size 812, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n",
      "Created a chunk of size 509, which is longer than the specified 500\n",
      "Created a chunk of size 823, which is longer than the specified 500\n",
      "Created a chunk of size 517, which is longer than the specified 500\n",
      "Created a chunk of size 560, which is longer than the specified 500\n",
      "Created a chunk of size 613, which is longer than the specified 500\n",
      "Created a chunk of size 973, which is longer than the specified 500\n",
      "Created a chunk of size 667, which is longer than the specified 500\n",
      "Created a chunk of size 570, which is longer than the specified 500\n",
      "Created a chunk of size 511, which is longer than the specified 500\n",
      "Created a chunk of size 603, which is longer than the specified 500\n",
      "Created a chunk of size 528, which is longer than the specified 500\n",
      "Created a chunk of size 700, which is longer than the specified 500\n",
      "Created a chunk of size 507, which is longer than the specified 500\n",
      "Created a chunk of size 606, which is longer than the specified 500\n",
      "Created a chunk of size 513, which is longer than the specified 500\n",
      "Created a chunk of size 610, which is longer than the specified 500\n",
      "Created a chunk of size 759, which is longer than the specified 500\n",
      "Created a chunk of size 519, which is longer than the specified 500\n",
      "Created a chunk of size 534, which is longer than the specified 500\n",
      "Created a chunk of size 861, which is longer than the specified 500\n",
      "Created a chunk of size 546, which is longer than the specified 500\n",
      "Created a chunk of size 682, which is longer than the specified 500\n",
      "Created a chunk of size 523, which is longer than the specified 500\n",
      "Created a chunk of size 600, which is longer than the specified 500\n",
      "Created a chunk of size 533, which is longer than the specified 500\n",
      "Created a chunk of size 548, which is longer than the specified 500\n",
      "Created a chunk of size 549, which is longer than the specified 500\n",
      "Created a chunk of size 617, which is longer than the specified 500\n",
      "Created a chunk of size 696, which is longer than the specified 500\n",
      "Created a chunk of size 555, which is longer than the specified 500\n",
      "Created a chunk of size 503, which is longer than the specified 500\n",
      "Created a chunk of size 654, which is longer than the specified 500\n",
      "Created a chunk of size 841, which is longer than the specified 500\n",
      "Created a chunk of size 683, which is longer than the specified 500\n",
      "Created a chunk of size 516, which is longer than the specified 500\n",
      "Created a chunk of size 549, which is longer than the specified 500\n",
      "Created a chunk of size 551, which is longer than the specified 500\n",
      "Created a chunk of size 605, which is longer than the specified 500\n",
      "Created a chunk of size 573, which is longer than the specified 500\n",
      "Created a chunk of size 514, which is longer than the specified 500\n",
      "Created a chunk of size 789, which is longer than the specified 500\n",
      "Created a chunk of size 764, which is longer than the specified 500\n",
      "Created a chunk of size 638, which is longer than the specified 500\n",
      "Created a chunk of size 614, which is longer than the specified 500\n",
      "Created a chunk of size 734, which is longer than the specified 500\n",
      "Created a chunk of size 597, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/langchain-ai/langchain/issues/11313\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = CSVLoader(\"./data/WineDataset.csv\",  encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# You might experience RequestEntityTooLargeError, to address this you can modify the batch size and chunk_size.\n",
    "#vector_store.add_documents(documents=docs)\n",
    "\n",
    "batch_size = 100  # Set batch size, adjust according to Azure's limitations\n",
    "for i in range(0, len(docs), batch_size):\n",
    "    batch = docs[i:i + batch_size]\n",
    "    vector_store.add_documents(documents=batch)  # Add smaller batches\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search\n",
    " \n",
    "Execute a pure vector similarity search using the similarity_search() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'id': 'Nzk3NzA3NGMtZDMyOS00N2NhLThjNjYtZDljNjI0ZmJhZWQ1', 'source': './data/WineDataset.csv', 'row': 1247}, page_content='In 2022, this wine won an IWC award for the 2011 vintage.\\nPrice: £166.99 per bottle\\nCapacity: 75CL\\nGrape: Chardonnay\\nSecondary Grape Varieties: \\nClosure: Natural Cork\\nCountry: France\\nUnit: 9.4\\nCharacteristics: Citrus Fruit, Almond, Biscuit, Bread\\nPer bottle / case / each: per bottle\\nType: White\\nABV: ABV 12.50%\\nRegion: \\nStyle: Rich & Toasty\\nVintage: 2012\\nAppellation:'),\n",
      " Document(metadata={'id': 'M2ExM2YwYmMtNmE5My00Y2FhLWI5MjgtYTNiM2ViZTZlNjBj', 'source': './data/WineDataset.csv', 'row': 700}, page_content='In 2022, this wine won an IWC award for the 2020 vintage.\\nPrice: £18.99 per bottle\\nCapacity: 75CL\\nGrape: Cabernet Sauvignon\\nSecondary Grape Varieties: Petit Verdot, Malbec, Merlot\\nClosure: Screwcap\\nCountry: South Africa\\nUnit: 10.9\\nCharacteristics: Tobacco, Black Plum, Blackberry, Blackcurrant, Leather\\nPer bottle / case / each: per bottle\\nType: Red\\nABV: ABV 14.50%\\nRegion: Stellenbosch\\nStyle: Savoury & Full Bodied\\nVintage: 2020\\nAppellation:'),\n",
      " Document(metadata={'id': 'NGJkZDEzMjUtZWVjYS00NTQxLWE0YjktZWJlNThhOTdlMjI2', 'source': './data/WineDataset.csv', 'row': 999}, page_content='In 2022, this wine won an IWC award for the 2017 vintage.\\nPrice: £27.99 per bottle\\nCapacity: 75CL\\nGrape: Cabernet Sauvignon\\nSecondary Grape Varieties: Merlot\\nClosure: Natural Cork\\nCountry: France\\nUnit: 10.9\\nCharacteristics: Cedar, Black Plum, Blackcurrant\\nPer bottle / case / each: per bottle\\nType: Red\\nABV: ABV 14.50%\\nRegion: Bordeaux\\nStyle: Savoury & Full Bodied\\nVintage: 2018\\nAppellation: Pauillac')]\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What are the most expensive wines that won an IWC award\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(docs)\n",
    "#print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search with relevance scores\n",
    " \n",
    "Execute a pure vector similarity search using the similarity_search_with_relevance_scores() method. Queries that don't meet the threshold requirements are exluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(metadata={'id': 'NDY3YzgwNGQtODFhZC00NmQ0LWEyOGMtNDVlMzU3NjU0MWE3', 'source': './data/WineDataset.csv', 'row': 126}, page_content='Title: Beefsteak Club Malbec 2021/22, Mendoza\\nDescription: Argentina is a paradise for steak and Malbec lovers – and no one does them better. This wine is a tribute to the dining clubs of the 18th and 19th centuries, which celebrated steak as a symbol of prosperity. The grapes come from high-altitude vineyards in some of Mendoza’s best sites, so you can expect delicious flavour in every glassful. It’s juicy and smooth with ripe black-fruit notes. Oak ageing gives it lush vanilla and gently spiced aromas – all balanced by a delicious freshness. It’s a real crowd pleaser and, naturally, incredible with steak.'),\n",
      "  0.6618109),\n",
      " (Document(metadata={'id': 'ZjRiNjJjNTUtZjM3My00ODZmLTg2YTYtM2JkOGYzOTM2MWJi', 'source': './data/WineDataset.csv', 'row': 78}, page_content=\"Title: Peter Lehmann 'The Barossan' Shiraz 2019/20, Barossa\\nDescription: With rolling hills, hot, dry summers and some of the world's oldest vines, Barossa is arguably the finest spot in the New World for full-bodied, juicy reds. And if you're looking for a wine that embodies all of this, you'd struggle to find better than this. Peter Lehmann Wines, one of the biggest names in Australian winemaking, spanned the length and breadth of this region to capture all of its best elements in this bottle. It's rich and bold with intense dark raspberry, plum, mocha and liquorice. Drink this alongside a beef stroganoff.\"),\n",
      "  0.65543765),\n",
      " (Document(metadata={'id': 'YzgyNDlmNGUtOThkYS00ZTM1LWI0MTUtNDcwOWQ2ZWU3YmJk', 'source': './data/WineDataset.csv', 'row': 458}, page_content=\"Title: Majestic Classics 12 Red Wine Case\\nDescription: A varied selection of delicious red wines, perfect for gatherings or enjoying with hearty roasts. It ticks all the boxes and you'll see why. This includes a juicy Spanish Tempranillo, a peppery South African Shiraz, a rich Argentinian Malbec and a French Rhone.\\nPrice: £90.00 per case\\nCapacity: Our\\nGrape: \\nSecondary Grape Varieties: \\nClosure: \\nCountry: \\nUnit: \\nCharacteristics: \\nPer bottle / case / each: per case\\nType: Red\\nABV: \\nRegion: \\nStyle: \\nVintage: \\nAppellation:\"),\n",
      "  0.6495939),\n",
      " (Document(metadata={'id': 'M2Q2M2M1ODYtMWUyNi00NDdlLWE5YmEtODc0NzlkM2M4ZGRl', 'source': './data/WineDataset.csv', 'row': 347}, page_content=\"Title: Santa Rita 'Medalla Real' Carménère 2019/21, Colchagua Valley\\nDescription: Carménère may be Chile’s flagship red grape. But did you know that its history stretches back to Bordeaux? When the tiny phylloxera bugs ravaged Europe in the nineteenth century, Bordeaux’s Carménère vines were a casualty. It had been a key component of some of the greatest claret at the time – but the vine was only saved by cuttings which had been taken to Chile.  So it’s no wonder that Santa Rita use Carménère to make this fantastically structured Gran Reserva, which is styled like a classic Bordeaux. It’s a plush, velvety-smooth wine, packed with intense flavours of blueberry, plum and cassis. The firm tannins make it ideal with red meat.\\nPrice: £13.99 per bottle\\nCapacity: 75CL\\nGrape: Carménère\\nSecondary Grape Varieties: \\nClosure: Natural Cork\\nCountry: Chile\\nUnit: 10.5\\nCharacteristics: Vanilla, Black Plum, Blackberry, Blackcurrant, Blueberry, Chocolate, Earth, Leather, Smoke, Tobacco\\nPer bottle / case / each: per bottle\\nType: Red\\nABV: ABV 14.00%\\nRegion: Central Valley\\nStyle: Bold & Spicy\\nVintage: 2021\\nAppellation: Colchagua Valley\"),\n",
      "  0.64955574)]\n"
     ]
    }
   ],
   "source": [
    "docs_and_scores = vector_store.similarity_search_with_relevance_scores(\n",
    "    query=\"Which red wines go well with red meat?\",\n",
    "    k=4,\n",
    "    score_threshold=0.64,\n",
    ")\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(docs_and_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search\n",
    "\n",
    "Execute hybrid search using the search_type or hybrid_search() method. Vector and nonvector text fields are queried in parallel, results are merged, and top matches of the unified result set are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Santa Rita 'Medalla Real' Carménère 2019/21, Colchagua Valley\n",
      "Description: Carménère may be Chile’s flagship red grape. But did you know that its history stretches back to Bordeaux? When the tiny phylloxera bugs ravaged Europe in the nineteenth century, Bordeaux’s Carménère vines were a casualty. It had been a key component of some of the greatest claret at the time – but the vine was only saved by cuttings which had been taken to Chile.  So it’s no wonder that Santa Rita use Carménère to make this fantastically structured Gran Reserva, which is styled like a classic Bordeaux. It’s a plush, velvety-smooth wine, packed with intense flavours of blueberry, plum and cassis. The firm tannins make it ideal with red meat.\n",
      "Price: £13.99 per bottle\n",
      "Capacity: 75CL\n",
      "Grape: Carménère\n",
      "Secondary Grape Varieties: \n",
      "Closure: Natural Cork\n",
      "Country: Chile\n",
      "Unit: 10.5\n",
      "Characteristics: Vanilla, Black Plum, Blackberry, Blackcurrant, Blueberry, Chocolate, Earth, Leather, Smoke, Tobacco\n",
      "Per bottle / case / each: per bottle\n",
      "Type: Red\n",
      "ABV: ABV 14.00%\n",
      "Region: Central Valley\n",
      "Style: Bold & Spicy\n",
      "Vintage: 2021\n",
      "Appellation: Colchagua Valley\n"
     ]
    }
   ],
   "source": [
    "# Perform a hybrid search using the search_type parameter\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"Which red wines go well with red meat?\",\n",
    "    k=3,\n",
    "    search_type=\"hybrid\",\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Majestic Classics 12 Red Wine Case\n",
      "Description: A varied selection of delicious red wines, perfect for gatherings or enjoying with hearty roasts. It ticks all the boxes and you'll see why. This includes a juicy Spanish Tempranillo, a peppery South African Shiraz, a rich Argentinian Malbec and a French Rhone.\n",
      "Price: £90.00 per case\n",
      "Capacity: Our\n",
      "Grape: \n",
      "Secondary Grape Varieties: \n",
      "Closure: \n",
      "Country: \n",
      "Unit: \n",
      "Characteristics: \n",
      "Per bottle / case / each: per case\n",
      "Type: Red\n",
      "ABV: \n",
      "Region: \n",
      "Style: \n",
      "Vintage: \n",
      "Appellation:\n"
     ]
    }
   ],
   "source": [
    "# Perform a hybrid search using the hybrid_search method\n",
    "docs = vector_store.hybrid_search(\n",
    "    query=\"Which red wines go well with red meat?\", k=3\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom schemas and queries\n",
    "\n",
    "This section shows you how to replace the default schema with a custom schema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new index with custom filterable fields \n",
    "\n",
    "This schema shows field definitions. It's the default schema, plus several new fields attributed as filterable. Because it's using the default vector configuration, you won't see vector configuration or vector profile overrides here. The name of the default vector profile is \"myHnswProfile\" and it's using a vector configuration of Hierarchical Navigable Small World (HNSW) for indexing and queries against the content_vector field.\n",
    "\n",
    "There's no data for this schema in this step. When you execute the cell, you should get an empty index on Azure AI Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hierarchical Navigable Small World (HNSW)\n",
    "### Purpose: \n",
    "HNSW is an approximate nearest neighbor (ANN) algorithm. It’s designed to quickly find the nearest vectors (similar documents or search results) to a query vector, while maintaining good accuracy.\n",
    "How It Works: HNSW uses a graph-based approach where data points (vectors) are stored as nodes in a multi-layer graph. When searching for the nearest neighbors, it navigates through these layers in a hierarchical manner. The higher layers of the graph contain fewer nodes but help in quickly narrowing down the search space, while lower layers contain more nodes for a more detailed search.\n",
    "### Advantages:\n",
    "Speed: HNSW is very fast for large datasets due to its approximate nature. It doesn't compare every vector in the dataset, instead navigating the graph structure to reach a result quickly.\n",
    "Scalability: It scales well with large datasets, making it ideal for search indexes where speed is a priority.\n",
    "Memory Efficient: It has optimized memory usage compared to brute-force methods.\n",
    "### Disadvantages:\n",
    "Approximate Results: Since it is an approximate algorithm, the search results may not always be the true nearest neighbors. However, the trade-off in accuracy is often minimal and acceptable for most applications.\n",
    "## 2. Exhaustive KNN (K-Nearest Neighbor)\n",
    "### Purpose: \n",
    "Exhaustive KNN is a brute-force nearest neighbor search algorithm. It computes the distance between the query vector and every other vector in the dataset, ensuring the most accurate nearest neighbors.\n",
    "How It Works: For each query, exhaustive KNN compares the query vector to all vectors in the dataset and returns the k vectors that are closest to the query based on a similarity measure (like cosine similarity or Euclidean distance).\n",
    "### Advantages:\n",
    "Accuracy: This method guarantees the exact nearest neighbors, making it the most accurate method.\n",
    "Simplicity: It’s straightforward in implementation, as it does not require building complex data structures like in HNSW.\n",
    "### Disadvantages:\n",
    "Speed: Exhaustive KNN is significantly slower than approximate methods, especially with large datasets, as it needs to compute distances for every vector in the dataset.\n",
    "Scalability: It becomes inefficient as the dataset grows larger, making it less suitable for real-time applications where speed is critical.\n",
    "Resource Intensive: Since it processes every vector in the dataset, it requires more computation and memory resources compared to HNSW.\n",
    "## When to Use:\n",
    "### HNSW:\n",
    "Ideal for large datasets and applications where speed is critical, like real-time search and recommendation systems.\n",
    "Suitable for use cases where approximate results are acceptable, such as similarity-based search in AI-driven applications.\n",
    "### Exhaustive KNN:\n",
    "Best for small to medium datasets or cases where absolute accuracy is required, such as scientific applications or high-precision recommendation systems.\n",
    "Suitable for batch processing scenarios where speed is not a priority but accuracy is paramount.\n",
    "## Summary:\n",
    "HNSW offers faster and more scalable performance with approximate results, making it the go-to choice for real-time, large-scale vector search applications.\n",
    "Exhaustive KNN provides exact results but is slower and less scalable, best used for small datasets or when absolute accuracy is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field to store the title\n",
    "    SearchableField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "index_name: str = \"langchain-vector-index-custom\"\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embedding_function,\n",
    "    fields=fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add data and perform a query that includes a filter\n",
    "\n",
    "This example adds data to the vector store based on the custom schema. It loads text into the title and source fields. The source field is filterable. The sample query in this section filters the results based on content in the source field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZDI4ZmIzNzktODIwZC00Yjc0LWJjMmYtN2JlM2JlN2MzOTFh',\n",
       " 'MDZlOWM5NmItMzFiYy00NmI2LWFhMzktYTMzMDA1MjYxNGVl',\n",
       " 'NmM0MjdiZjYtZDNiMi00MGUyLWI2NjUtZjVkOGNhYmI3MDFi']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data in the metadata dictionary with a corresponding field in the index will be added to the index.\n",
    "# In this example, the metadata dictionary contains a title, a source, and a random field.\n",
    "# The title and the source are added to the index as separate fields, but the random value is ignored because it's not defined in the schema.\n",
    "# The random field is only stored in the metadata field.\n",
    "vector_store.add_texts(\n",
    "    [\"Test 1\", \"Test 2\", \"Test 3\"],\n",
    "    [\n",
    "        {\"title\": \"Title 1\", \"source\": \"A\", \"random\": \"10290\"},\n",
    "        {\"title\": \"Title 2\", \"source\": \"A\", \"random\": \"48392\"},\n",
    "        {\"title\": \"Title 3\", \"source\": \"B\", \"random\": \"32893\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 'NmM0MjdiZjYtZDNiMi00MGUyLWI2NjUtZjVkOGNhYmI3MDFi', 'title': 'Title 3', 'source': 'B', 'random': '32893'}, page_content='Test 3'),\n",
       " Document(metadata={'id': 'ZDI4ZmIzNzktODIwZC00Yjc0LWJjMmYtN2JlM2JlN2MzOTFh', 'title': 'Title 1', 'source': 'A', 'random': '10290'}, page_content='Test 1'),\n",
       " Document(metadata={'id': 'MDZlOWM5NmItMzFiYy00NmI2LWFhMzktYTMzMDA1MjYxNGVl', 'title': 'Title 2', 'source': 'A', 'random': '48392'}, page_content='Test 2')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vector_store.similarity_search(query=\"Test 3 source1\", k=3, search_type=\"hybrid\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 'ZDI4ZmIzNzktODIwZC00Yjc0LWJjMmYtN2JlM2JlN2MzOTFh', 'title': 'Title 1', 'source': 'A', 'random': '10290'}, page_content='Test 1'),\n",
       " Document(metadata={'id': 'MDZlOWM5NmItMzFiYy00NmI2LWFhMzktYTMzMDA1MjYxNGVl', 'title': 'Title 2', 'source': 'A', 'random': '48392'}, page_content='Test 2')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vector_store.similarity_search(\n",
    "    query=\"Test 3 source1\", k=3, search_type=\"hybrid\", filters=\"source eq 'A'\"\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new index with a scoring profile\n",
    "\n",
    "Here's another custom schema that includes a scoring profile definition. A scoring profile is used for relevance tuning of nonvector content, which is helpful in hybrid search scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    FreshnessScoringFunction,\n",
    "    FreshnessScoringParameters,\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "#  Azure OpenAI is your provider.\n",
    "embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=azure_deployment,\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    ")\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field to store the title\n",
    "    SearchableField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    # Additional data field for last doc update\n",
    "    SimpleField(\n",
    "        name=\"last_update\",\n",
    "        type=SearchFieldDataType.DateTimeOffset,\n",
    "        searchable=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "]\n",
    "# Adding a custom scoring profile with a freshness function\n",
    "sc_name = \"custom_scoring_profile\"\n",
    "sc = ScoringProfile(\n",
    "    name=sc_name,\n",
    "    text_weights=TextWeights(weights={\"title\": 5}),\n",
    "    function_aggregation=\"sum\",\n",
    "    functions=[\n",
    "        FreshnessScoringFunction(\n",
    "            field_name=\"last_update\",\n",
    "            boost=100,\n",
    "            parameters=FreshnessScoringParameters(boosting_duration=\"P2D\"),\n",
    "            interpolation=\"linear\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "index_name = \"langchain-vector-custom-scoring-profile\"\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    fields=fields,\n",
    "    scoring_profiles=[sc],\n",
    "    default_scoring_profile=sc_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vmunagal\\AppData\\Local\\Temp\\ipykernel_35132\\433022458.py:4: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  today = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n",
      "C:\\Users\\vmunagal\\AppData\\Local\\Temp\\ipykernel_35132\\433022458.py:5: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  yesterday = (datetime.utcnow() - timedelta(days=1)).strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n",
      "C:\\Users\\vmunagal\\AppData\\Local\\Temp\\ipykernel_35132\\433022458.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  one_month_ago = (datetime.utcnow() - timedelta(days=30)).strftime(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ZTg2MGY1M2YtZThmNC00ODYzLTlkYWYtNzEzMDg4NWU4OGI4',\n",
       " 'YjNjOGY3YmMtOTcxMi00ZTk2LWIzMTAtYzg5NDQ0ZTdiYTdl',\n",
       " 'MWFiN2VjMTktMWQ4My00NWQ4LWFkMjktNmQ0ZDdhOWFmMGRi']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding same data with different last_update to show Scoring Profile effect\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "today = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n",
    "yesterday = (datetime.utcnow() - timedelta(days=1)).strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n",
    "one_month_ago = (datetime.utcnow() - timedelta(days=30)).strftime(\n",
    "    \"%Y-%m-%dT%H:%M:%S-00:00\"\n",
    ")\n",
    "\n",
    "vector_store.add_texts(\n",
    "    [\"Test 1\", \"Test 1\", \"Test 1\"],\n",
    "    [\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"10290\",\n",
    "            \"last_update\": today,\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"48392\",\n",
    "            \"last_update\": yesterday,\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"32893\",\n",
    "            \"last_update\": one_month_ago,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 'ZTg2MGY1M2YtZThmNC00ODYzLTlkYWYtNzEzMDg4NWU4OGI4', 'title': 'Title 1', 'source': 'source1', 'random': '10290', 'last_update': '2024-10-13T17:30:21-00:00'}, page_content='Test 1'),\n",
       " Document(metadata={'id': 'YjNjOGY3YmMtOTcxMi00ZTk2LWIzMTAtYzg5NDQ0ZTdiYTdl', 'title': 'Title 1', 'source': 'source1', 'random': '48392', 'last_update': '2024-10-12T17:30:21-00:00'}, page_content='Test 1'),\n",
       " Document(metadata={'id': 'MWFiN2VjMTktMWQ4My00NWQ4LWFkMjktNmQ0ZDdhOWFmMGRi', 'title': 'Title 1', 'source': 'source1', 'random': '32893', 'last_update': '2024-09-13T17:30:21-00:00'}, page_content='Test 1')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vector_store.similarity_search(query=\"Test 1\", k=3, search_type=\"similarity\")\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
